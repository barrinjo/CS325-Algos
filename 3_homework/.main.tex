\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{multicol}
\setlength{\columnsep}{8cm}

\title{CS325 Homework 3}
\author{Josuha Barringer \\ Prof. Schutfort}
\date{7 February 2020}

\begin{document}

\maketitle

\section*{Problem 1: Rod Cutting}

We define a rod with length 3, whose length prices are as follows, [1, 8, 10].  Using the greedy algorithm, the value per inch for each length would be [$\frac{1}{1}$, $\frac{8}{2}$, $\frac{10}{3}$], or [1, 4, 3.$\overline{333}$].  The greedy algorithm would first cut off a rod of length 2, since it has the highest value per inch of 4.  The remaining 1 inch cannot be cut any more, so the algorithm would finish with a total value of 9.  The actual highest possible value would be to use no cuts and end with a total value of 10.  Clearly, the "greedy" strategy doesn't work in this situation.

\section*{Problem 2: Modified Rod Cutting}

I modified the book's Bottom-Up-Cut-Rod Method for this problem:\\

\textsc{Bottom-Up-Cut-Rod$(p,n,cut\_price)$}

    \begin{verbatim}
        1 let r[0..n] be a new array
        2 r[0] = 0
        3 for j = 1 to n
        4     q = -infinity
        5     for i = 1 to j
        6         q = max(q, p[i] + r[j - i] - cut_price)
        7     r[j] - q
        8 return r[n]
    \end{verbatim}
    
This modified algorithm takes a third argument, "cut\_price".  On line 6, the previous max variable q is now compared with the proposed new cut summed with the memo lookup for length optimization for the remaining piece, \textit{with the price of the cut subtracted from the total}.  This modification should allow custom cut prices, as well as account for the cut price during the rod cutting optimization.

\section*{Problem 3}

\subsection*{a)}

\subsubsection*{Recursive 0-1 Knapsack:}

The greedy strategy doesn't work for 0-1 knapsack like it does with fractional knapsack, so the recursion can't rely on wt/val ratios.  Starting with the arguments W (weight available), val[] (item values), wt[] (item weights), and i (number of items), we need to first check that the item i can fit in the knapsack at all, otherwise we will fail the problem.  If we've verified the item can fit in the knapsack, we will recursively take the max value between the value of the knapsack if we include item i, and if we don't.  The recursive pattern will be i-1, since we must check every possible item.\\

\textsc{Recursive Knapsack$(W, val[], wt[], i)$}

\begin{verbatim}
    1 if(W < wt[i])
    2     return knapsack(W, val[], wt[], i-1)
    3 else
    4     return max(knapsack(W, val[], wt[], i-1),
    5               val[i] + knapsack(W-wt[i], val[], wt[], i-1))
\end{verbatim}

\subsubsection*{Dynamic Programming 0-1 Knapsack:}

For the dynamic programming solution to the knapsack problem, we need to iterate through W and i, and at each new location in the 2D array, evaluate that location's value.  Firstly, we'll allocate a memo of that is [W + 1][i + 1] to create an outside bound for the 2D array. If W or i is equal to zero, the location value will be zero as well.  Next, we will check if the item can fit in the knapsack with the given weight.  If the item does not fit, then the value in the current location will be the same as the value for the previous item(i-1) of the same weight (w).  Finally, if the item can fit in knapsack at the given weight, then we have to take the max of two values: the value of the previous item (i-1) of the same weight (w), or the value of our proposed new item (val[i]) summed with the value of the previous items (i-1) of a new weight including the new item (w-wt[i]).  Whichever of those two is of greater value will be the value at this location.  This algorithm will result in the greatest optimization for the 0-1 knapsack problem.

\textsc{DP Knapsack$(W, wt[], val[], item)$}

\begin{verbatim}
    1 memo = [W + 1][item + 1]
    2 for(i = 0; i < item + 1; i++) {
    3     for(w = 0; w < W + 1; w++)
    4         if(w == 0 || i == 0)
    5             memo[i][w] = 0
    6         else if (wt[i] > W)
    7             memo[i][w] = memo[i - 1][w]
    8         else
    9             memo[i][w] = max(memo[i - 1][w],
    10                         val[i] + memo[i - 1][w - wt[i]])
    11 return memo[W][item]
\end{verbatim}

\begin{verbatim}
    
\end{verbatim}

\subsection*{c)}

\begin{multicols}{3}

        \begin{tabular}{||c c c c||} 
        \hline
        n & W & Rec time(s) & DP time(s) \\ [0.5ex] 
        \hline\hline
        10 & 30 & 0.00011 & 0.0001 \\
        \hline
        12 & 30 & 0.00005 & 0.00016 \\
        \hline
        14 & 30 & 0.00078 & 0.00013 \\
        \hline
        16 & 30 & 0.00225 & 0.00015 \\
        \hline
        18 & 30 & 0.00053 & 0.00021 \\
        \hline
        20 & 30 & 0.00291 & 0.00019 \\
        \hline
        22 & 30 & 0.00198 & 0.00021 \\
        \hline
        24 & 30 & 0.01346 & 0.00023 \\
        \hline
        26 & 30 & 0.0012 & 0.00024 \\
        \hline
        28 & 30 & 0.0032 & 0.00026 \\
        \hline
        30 & 30 & 0.00663 & 0.0003 \\
        \hline\hline
        10 & 60 & 0.00019 & 0.00028 \\
        \hline
        12 & 60 & 0.00073 & 0.00032 \\
        \hline
        14 & 60 & 0.00161 & 0.00026 \\
        \hline
        16 & 60 & 0.0019 & 0.0003 \\
        \hline
        18 & 60 & 0.01252 & 0.00034 \\
        \hline
        20 & 60 & 0.02574 & 0.00039 \\
        \hline
        22 & 60 & 0.07363 & 0.00044 \\
        \hline
        24 & 60 & 0.15368 & 0.00044 \\
        \hline
        26 & 60 & 0.33396 & 0.00049 \\
        \hline
        28 & 60 & 0.15877 & 0.00054 \\
        \hline
        30 & 60 & 1.03528 & 0.00057 \\
        \hline
        \end{tabular}
        
        \begin{tabular}{||c c c c||} 
        \hline
        n & W & Rec time(s) & DP time(s) \\ [0.5ex] 
        \hline\hline
        10 & 90 & 0.00029 & 0.00027 \\
        \hline
        12 & 90 & 0.00125 & 0.00032 \\
        \hline
        14 & 90 & 0.00525 & 0.00038 \\
        \hline
        16 & 90 & 0.01597 & 0.00043 \\
        \hline
        18 & 90 & 0.03986 & 0.0005 \\
        \hline
        20 & 90 & 0.16315 & 0.00054 \\
        \hline
        22 & 90 & 0.41266 & 0.00063 \\
        \hline
        24 & 90 & 0.76616 & 0.00134 \\
        \hline
        26 & 90 & 3.33157 & 0.00076 \\
        \hline
        28 & 90 & 4.93452 & 0.0008 \\
        \hline
        30 & 90 & 16.52896 & 0.00079 \\
        \hline\hline
        10 & 120 & 0.00033 & 0.00035 \\
        \hline
        12 & 120 & 0.00183 & 0.00055 \\
        \hline
        14 & 120 & 0.00563 & 0.00049 \\
        \hline
        16 & 120 & 0.02067 & 0.00056 \\
        \hline
        18 & 120 & 0.06837 & 0.00069 \\
        \hline
        20 & 120 & 0.17896 & 0.00071 \\
        \hline
        22 & 120 & 0.67432 & 0.00079 \\
        \hline
        24 & 120 & 3.29509 & 0.00085 \\
        \hline
        26 & 120 & 6.74058 & 0.00092 \\
        \hline
        28 & 120 & 26.70228 & 0.00105 \\
        \hline
        30 & 120 & 184.42888 & 0.00113\\
        \hline
        \end{tabular}

\end{multicols}
    
\subsubsection*{}

\includegraphics[height=7cm]{dp w30.png}

The line of best fit for the DP data was linear, $y = mx + b$.  This matches the predicted running time for the algorithm.  Since we only iterate over each memo space one time, the running time should be linear.  The line of best fit was \boxed{y = 0.00000859091x - 0.000036==263636}

\subsubsection*{}

\includegraphics[height=7cm]{rec v dp W 30.png}

The line of best fit for the recursive knapsack data is $y = am^x$.  This matches the prediction of an exponential growth for recursive knapsack.  The line of best fit is \boxed{y = 0.000024047x + 1.21762}

\subsubsection*{}

\includegraphics[height=7cm]{W graphs dp.png}

This graph shows the side by sides of all the dynamic programming knapsack data.  The lines are identifiable as follows: green, W=30; blue, W=60; yellow, W=90; black, W=120.  With each increase of W, the time it takes the dynamic programming algorithm to optimize the knapsack is linear, with the slope increasing slightly.

\subsubsection*{}

\includegraphics[height=7cm]{W graphs recursive.png}

This graph shows the side by sides of all the recursive knapsack data.  The lines are identifiable as follows: green, W=30; blue, W=60; yellow, W=90; black, W=120.  With each increase of W, the time it takes the recursive algorithm to optimize the knapsack stays exponential, with the growth rate increasing with each total weight increase.

\subsubsection*{}

\includegraphics[width=\linewidth]{total loglog.png}

These 4 graphs show loglog growth-rate comparisons of the dynamic programming and recursive algorithm for each of the 4 W values. The graphs are identifiable as follows: green, W=30; blue, W=60; yellow, W=90; black, W=120.  It can be seen in each graph that no matter the W size, the recursive algorithm takes a significantly longer time to complete.  As W increases, the difference in growth rates increases as well.

\subsection*{d)}

For the data collection, I used nested loops to test different values of n and W for each algorithm.  The n loop goes in iterations of +2, between the values of 10 and 30.  The W loop does in iterations of 30, between 30 and 120.  I time and run each algorithm on the same randomly generated data sets with the n and W values.  This meant that I had tested each algorithm under 60 different conditions of n and W.  What I found was that increases of both n and W increased running time, but W seemed to effect the running time with a much greater magnitude.  Part of this is likely due to the fact that the W value gets much larger than n.  

\section*{Problem 4}

\subsection*{a)}

This problem is almost identical to the knapsack problem, so the pseudo-code will resemble it quite a bit.  We've got a list of items, with corresponding weights and values.  The main difference between 0-1 knapsack and shopping spree is that instead of optimizing one knapsack, we're optimizing F knapsacks.  To implement this code, all we have to do is loop the knapsack algorithm F times, using each family member's corresponding max weight value.  Once the knapsack code has run once for each family member, we sum the value to get the total optimized value for this problem.

\textsc{Shopping Spree(F[], wt[], val[], item):}
    
\begin{verbatim}
    1  subtotals = [F.length()]
    2  for(int f = 0; f < F.length(); f++)
    3      memo[F[f]][item + 1]
    4      for(int i = 0; i < item + 1; i++)
    5          for(int w = 0; w < F[f]; w++)
    6              if(w == 0 || i == 0)
    7                  memo[i][w] = 0
    8              else if (wt[i] > F[f])
    9                  memo[i][w] = memo[i - 1][w]
    10             else
    11                 memo[i][w] = max(memo[i-1][w],
    12                 val[i] + memo[i-1][w-wt[i]])
    13     subtotals[f] = memo[F[f]][item]
    14 return sum(subtotals)
                    
\end{verbatim}

\subsection*{b)}

Since dynamic programming algorithms memoize previous problems, each combination of family member, weight, and item only need to be checked once each.  Because of this, the running time given N items, a family size of F, who can each carry M$_i$ pounds will be $O(NFM_i)$

\end{document}
